{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO6c1KV2Nc4AWEzHwC+V1pS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":[" # Convolutional networks\n","In this tutorial, you will implement a simple convolutional neural network (CNN) with pytorch to classifiy images of handwritten digits.\n","\n","**Make sure you are setting the runtime to GPU**\n","\n","\n","This tutorial is based on convnet turorials from AMMI computer vision course 2021"],"metadata":{"id":"NgGGfPXpgoce"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"mJmPZ_YpgQqi","executionInfo":{"status":"ok","timestamp":1681363891500,"user_tz":0,"elapsed":9413,"user":{"displayName":"Faisal Mohamed","userId":"11607485401005900946"}}},"outputs":[],"source":["import random\n","\n","import PIL\n","import imageio\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import skimage.transform\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.utils.data\n","import torchvision\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms\n","from IPython import display"]},{"cell_type":"markdown","source":["Useful methods for visualization"],"metadata":{"id":"fzr92rXWhr1C"}},{"cell_type":"code","source":["%matplotlib inline\n","\n","def show(img):\n","    \"\"\"Show PyTorch tensor img as an image in matplotlib.\"\"\"\n","    npimg = img.cpu().detach().numpy()\n","    plt.imshow(np.transpose(npimg, (1, 2, 0)), interpolation='nearest')\n","    plt.grid(False)\n","    plt.gca().axis('off')\n","\n","def display_thumb(img):\n","  display.display(transforms.Resize(128)(img))"],"metadata":{"id":"MxORyelAhM6k","executionInfo":{"status":"ok","timestamp":1681363891940,"user_tz":0,"elapsed":443,"user":{"displayName":"Faisal Mohamed","userId":"11607485401005900946"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Use GPU if available \n","device = 'cuda' if torch.cuda.is_available() else 'cpu'"],"metadata":{"id":"Oq35Ut-7hwK0","executionInfo":{"status":"ok","timestamp":1681363891941,"user_tz":0,"elapsed":6,"user":{"displayName":"Faisal Mohamed","userId":"11607485401005900946"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Load the training and test dataset.\n","mnist_train = datasets.MNIST('/tmp/mnist', train=True, download=True, transform=transforms.ToTensor())\n","mnist_test = datasets.MNIST('/tmp/mnist', train=False, download=True, transform=transforms.ToTensor())\n","\n","# Size of the batches the data loader will produce.\n","batch_size = 64\n","\n","# This creates the dataloaders.\n","train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n","test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"giPNFPQGh4Ry","executionInfo":{"status":"ok","timestamp":1681363894261,"user_tz":0,"elapsed":2325,"user":{"displayName":"Faisal Mohamed","userId":"11607485401005900946"}},"outputId":"128c166c-3be9-42f5-a9d1-60d29aeb90c8"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /tmp/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9912422/9912422 [00:00<00:00, 111705910.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting /tmp/mnist/MNIST/raw/train-images-idx3-ubyte.gz to /tmp/mnist/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /tmp/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28881/28881 [00:00<00:00, 12419078.72it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting /tmp/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to /tmp/mnist/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /tmp/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1648877/1648877 [00:00<00:00, 35323908.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting /tmp/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to /tmp/mnist/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /tmp/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4542/4542 [00:00<00:00, 280299.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting /tmp/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to /tmp/mnist/MNIST/raw\n","\n"]}]},{"cell_type":"code","source":["img, label = next(iter(mnist_train))\n","print(f\"Image label:{label}\")\n","show(img)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"VW24BkxRGEpj","executionInfo":{"status":"ok","timestamp":1681363909043,"user_tz":0,"elapsed":423,"user":{"displayName":"Faisal Mohamed","userId":"11607485401005900946"}},"outputId":"cd0755ee-a485-45c5-bf64-469544483cda"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Image label:5\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["# Training Function \n","def train(model, criterion, data_loader, optimizer, num_epochs):\n","    \"\"\"Simple training loop for a PyTorch model.\"\"\" \n","    \n","    # Make sure model is in training mode.\n","    model.train()\n","    \n","    # Move model to the device (CPU or GPU).\n","    model.to(device)\n","    \n","    # Exponential moving average of the loss.\n","    ema_loss = None\n","    \n","    # Loop over epochs.\n","    for epoch in range(num_epochs):\n","        \n","      # Loop over data.\n","      for batch_idx, (data, target) in enumerate(data_loader):\n","            \n","          # Forward pass.\n","          output = model(data.to(device))\n","          loss = criterion(output.to(device), target.to(device))\n","          \n","          # Backward pass.\n","          optimizer.zero_grad()\n","          loss.backward()\n","          optimizer.step()\n","          \n","          # NOTE: It is important to call .item() on the loss before summing.\n","          if ema_loss is None:\n","            ema_loss = loss.item()\n","          else:\n","            ema_loss += (loss.item() - ema_loss) * 0.01 \n","          \n","      # Print out progress the end of epoch.\n","      print('Train Epoch: {} \\tLoss: {:.6f}'.format(\n","            epoch, ema_loss),\n","      )\n","              \n","# Testing Function               \n","def test(model, data_loader):\n","    \"\"\"Measures the accuracy of a model on a data set.\"\"\" \n","    # Make sure the model is in evaluation mode.\n","    model.eval()\n","    correct = 0\n","\n","    # We do not need to maintain intermediate activations while testing.\n","    with torch.no_grad():\n","        \n","        # Loop over test data.\n","        for data, target in data_loader:\n","          \n","            # Forward pass.\n","            output = model(data.to(device))\n","            \n","            # Get the label corresponding to the highest predicted probability.\n","            pred = output.argmax(dim=1, keepdim=True)\n","            \n","            # Count number of correct predictions.\n","            correct += pred.cpu().eq(target.view_as(pred)).sum().item()\n","\n","    # Print test accuracy.\n","    percent = 100. * correct / len(data_loader.dataset)\n","    print(f'Accuracy: {correct} / {len(data_loader.dataset)} ({percent:.0f}%)')\n","    return percent\n","   "],"metadata":{"id":"YPtPP-Vyh6qF","executionInfo":{"status":"ok","timestamp":1681338052685,"user_tz":0,"elapsed":2,"user":{"displayName":"Faisal Mohamed","userId":"11607485401005900946"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## ConvNet Model"],"metadata":{"id":"DzWNJMhiiWl6"}},{"cell_type":"code","source":["class ConvolutionalNetwork(nn.Module):\n","  \"\"\"Simple convolutional network.\"\"\"\n","  \n","  def __init__(self, image_side_size, num_classes, in_channels=1):\n","      super(ConvolutionalNetwork, self).__init__()\n","      \n","      self.in_channels = in_channels\n","      self.num_classes = num_classes\n","      self.image_side_size = image_side_size\n","      # Fill these in:\n","      ##########################################################################\n","      # TODO: Implement a convulutional and a linear part.                     #\n","      # Hint: see forward() to understand how they should work together.       #\n","      # Hint: use the method get_conv_network_output to get the size of the input to the linear part\n","      ##########################################################################       \n","\n","      # Define the convolution part, self.conv_network, you can use parameters in the slides as a starting point\n","      # Get the output size from the convolution part using the method get_conv_network_output\n","      # Define the linear part, self.linear\n","      \n","      \n","  def forward(self, x):\n","      x = self.conv_network(x)\n","      x = self.linear(x.view(x.size(0), -1))\n","      return x\n","\n","  def get_conv_network_output(self, ):\n","      dummy_x = torch.zeros(1, self.in_channels, self.image_side_size, self.image_side_size)\n","      conv_output = self.conv_network(dummy_x)\n","      conv_output_size = torch.prod(torch.tensor(conv_output.shape))\n","      return conv_output_size\n","\n","    \n","# Create and train convolutional network.\n","# The accuracy should be around 96%.\n","\n","###########################################################################\n","# TODO: Create criterion and optimize here.                               #\n","###########################################################################\n","\n","\n","###########################################################################\n","# TODO: Train the model and test it on the test set\n","###########################################################################\n"],"metadata":{"id":"2tSLf0tHiRu6","executionInfo":{"status":"ok","timestamp":1681338063506,"user_tz":0,"elapsed":282,"user":{"displayName":"Faisal Mohamed","userId":"11607485401005900946"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Print the testing accuracy it should be around 96%"],"metadata":{"id":"FQMzhVk8jtab"},"execution_count":null,"outputs":[]}]}